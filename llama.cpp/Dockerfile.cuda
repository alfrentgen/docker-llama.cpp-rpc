ARG LLAMA_SOURCE_DIR="/app/llama.cpp"
ARG INSTALLATION_PATH="${LLAMA_SOURCE_DIR}/install"
ARG BUILD_DIR="build"
ARG BUILD_CONFIG_TYPE="Release"

FROM nvidia/cuda:12.4.1-devel-ubuntu22.04 AS builder
WORKDIR /app

ARG LLAMACPP_REPO="https://github.com/ggerganov/llama.cpp.git"
# It may be name of branch, tag or commit hash
ARG LLAMACPP_VERSION="master"

# To get latest tag use this:
# git -c 'versionsort.suffix=-' ls-remote --tags --sort='v:refname' \
#    "https://github.com/ggerganov/llama.cpp.git" 'b*' | \
#    tail --lines=1 | cut --delimiter='/' --fields=3
# For details see here: https://stackoverflow.com/questions/8932389/git-shallow-clone-to-specific-tag)

# Install dependencies
RUN set -xe \
&& apt update -q \
&& apt install -fyq bash wget git make g++ cmake ninja-build \
#&& apt install -fyq cmake-curses-gui \
&& apt clean

# Clone repo
RUN set -xe \
 && git clone --branch "$LLAMACPP_VERSION" --depth 1 "$LLAMACPP_REPO"

# Build binaries
ARG LLAMA_SOURCE_DIR
ARG INSTALLATION_PATH
ARG BUILD_DIR
ARG BUILD_CONFIG_TYPE
WORKDIR ${LLAMA_SOURCE_DIR}
RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1
RUN set -xe \
 && export LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs/:$LD_LIBRARY_PATH \
 #&& GGML_CUDA=ON GGML_RPC=ON make -j$(nproc) llama-server llama-cli llama-embedding rpc-server libggml.so libllama.so
 && cmake -G "Ninja Multi-Config" -B build -DGGML_CUDA=ON -DGGML_RPC=ON -DGGML_AVX=ON -DGGML_AVX2=ON -DGGML_CCACHE=OFF \
 && cmake --build ${BUILD_DIR} --config ${BUILD_CONFIG_TYPE} \
 && cmake --install ${BUILD_DIR} --prefix="${INSTALLATION_PATH}"




FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04
WORKDIR /app

# Install basic dependencies
RUN set -xe \
 && apt update -q \
 && apt install -fyq libgomp1 \
 && apt clean

# Create folders
RUN set -xe \
 && mkdir -pv /app/models

# Copy compiled tools
ARG INSTALLATION_PATH
ARG BIN_BUILD_DIR="${INSTALLATION_PATH}/bin"
ARG LIB_BUILD_DIR="${INSTALLATION_PATH}/lib"
COPY --from=builder ${LIB_BUILD_DIR}/libllama.so /usr/lib/x86_64-linux-gnu
COPY --from=builder ${LIB_BUILD_DIR}/libggml.so /usr/lib/x86_64-linux-gnu
COPY --from=builder ${BIN_BUILD_DIR}/llama-cli .
COPY --from=builder ${BIN_BUILD_DIR}/llama-embedding .
COPY --from=builder ${BIN_BUILD_DIR}/llama-server .

ARG BUILD_DIR
ARG BUILD_CONFIG_TYPE
ARG LLAMA_SOURCE_DIR
ARG RPC_PATH="${LLAMA_SOURCE_DIR}/${BUILD_DIR}/bin/${BUILD_CONFIG_TYPE}"
COPY --from=builder ${RPC_PATH}/rpc-server .

# Init entrypoint
ADD entrypoint.sh .
ENTRYPOINT ["/app/entrypoint.sh"]
