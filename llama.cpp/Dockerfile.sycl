ARG LLAMA_SOURCE_DIR="/app/llama.cpp"
ARG INSTALLATION_PATH="${LLAMA_SOURCE_DIR}/install"
ARG BUILD_DIR="build"
ARG BUILD_CONFIG_TYPE="Release"
ARG IMAGE_NAME="intel/deep-learning-essentials:2025.0.0-0-devel-ubuntu22.04"

FROM ${IMAGE_NAME} AS builder
WORKDIR /app

ARG LLAMACPP_REPO="https://github.com/ggerganov/llama.cpp.git"
# It may be name of branch, tag or commit hash
ARG LLAMACPP_VERSION="master"

# To get latest tag use this:
# git -c 'versionsort.suffix=-' ls-remote --tags --sort='v:refname' \
#    "https://github.com/ggerganov/llama.cpp.git" 'b*' | \
#    tail --lines=1 | cut --delimiter='/' --fields=3
# For details see here: https://stackoverflow.com/questions/8932389/git-shallow-clone-to-specific-tag)

# Install dependencies
RUN set -xe \
&& apt update -q \
&& apt install -fyq bash wget git make g++ cmake ninja-build \
#&& apt install -fyq cmake-curses-gui \
&& apt clean

# Clone repo
RUN set -xe \
 && git clone --branch "$LLAMACPP_VERSION" --depth 1 "$LLAMACPP_REPO"

# Build binaries
ARG LLAMA_SOURCE_DIR
ARG INSTALLATION_PATH
ARG BUILD_DIR
ARG BUILD_CONFIG_TYPE
WORKDIR ${LLAMA_SOURCE_DIR}
RUN set -xe \
 #&& GGML_RPC=ON make -j$(nproc) llama-server llama-cli llama-embedding rpc-server libggml.so libllama.so
 && cmake -G "Ninja Multi-Config" -B build -DGGML_CUDA=OFF -DGGML_NATIVE=OFF -DGGML_CCACHE=OFF -DGGML_STATIC=OFF \
 -DGGML_SYCL=ON -DGGML_SYCL_F16=ON -DGGML_RPC=ON -DCMAKE_C_COMPILER=icx -DCMAKE_CXX_COMPILER=icpx \
 && cmake --build ${BUILD_DIR} --config ${BUILD_CONFIG_TYPE} \
 && cmake --install ${BUILD_DIR} --prefix="${INSTALLATION_PATH}"



FROM ${IMAGE_NAME}
WORKDIR /app

# Install basic dependencies
RUN set -xe \
 && apt update -q \
 && apt install -fyq libgomp1 \
 && apt clean

# Create folders
RUN set -xe \
 && mkdir -pv /app/models

# Copy compiled tools
ARG INSTALLATION_PATH
ARG BIN_BUILD_DIR="${INSTALLATION_PATH}/bin"
ARG LIB_BUILD_DIR="${INSTALLATION_PATH}/lib"
COPY --from=builder ${LIB_BUILD_DIR}/*.so /usr/lib/x86_64-linux-gnu/
COPY --from=builder ${BIN_BUILD_DIR}/llama-cli .
COPY --from=builder ${BIN_BUILD_DIR}/llama-embedding .
COPY --from=builder ${BIN_BUILD_DIR}/llama-server .

ARG BUILD_DIR
ARG BUILD_CONFIG_TYPE
ARG LLAMA_SOURCE_DIR
ARG RPC_PATH="${LLAMA_SOURCE_DIR}/${BUILD_DIR}/bin/${BUILD_CONFIG_TYPE}"
COPY --from=builder ${RPC_PATH}/rpc-server .

# Init entrypoint
ADD entrypoint.sh .
ENTRYPOINT ["/app/entrypoint.sh"]
